[GENERAL]
pop_size             = 10
consistency_evals    = 5
available_layers     = {'Dense': 2,
                        'Dropout': 1}
available_optimizers = 'Adam'


[GENOME]
dtype                = 'float16'
recurrent_graph      = True
recurrent_stateful   = True
recurrent_init       = 'layer_identity'
input_scaling        = 'auto'
merge_method         = 'concat'
preprocessing_layers = None
input_layers         = None
output_layers        = [{'class_name': 'Dense', 'config': {'units': 1, 'activation': 'sigmoid'}}]


[SPECIATION]
spec_type            = 'dynamic'
spec_species_count   = 3
spec_fitness_func    = 'median'
spec_distance        = 0.3
spec_distance_dec    = 0.05
spec_distance_calc   = 'basic'
spec_genome_elitism  = 2
spec_min_offspring   = 1
spec_reprod_thres    = 0.5
spec_max_stagnation  = 10
spec_species_elitism = 2
spec_rebase_repr     = True
spec_reinit_extinct  = False


[EVOLUTION]
mutation_degree          = 0.3
mutation_add_conn_prob   = 1
mutation_add_node_prob   = 1
mutation_rem_conn_prob   = 1
mutation_rem_node_prob   = 0
mutation_node_layer_prob = 0
mutation_hyperparam_prob = 0
crossover_prob           = 0


[LAYER_DENSE]
units       = {'min': 4, 'max': 32, 'step': 4}
activation  = ['linear', 'relu', 'sigmoid', 'softmax', 'tanh']
kernel_init = ['glorot_normal', 'he_normal']
bias_init   = 'zeros'


[LAYER_DROPOUT]
dropout_rate = {'min': 0.1, 'max': 0.4, 'step': 0.1, 'stddev': 0.1}


[OPTIMIZER_ADAM]
learning_rate = {'min': 0.0001, 'max': 0.1, 'step': 0.0001, 'stddev': 0.02}
beta_1        = {'min': 0.6, 'max': 1.5, 'step': 0.05, 'stddev': 0.2}
beta_2        = {'min': 0.8, 'max': 1.2, 'step': 0.001, 'stddev': 0.1}
epsilon       = {'min': 1e-8, 'max': 1e-6, 'step': 1e-8}
